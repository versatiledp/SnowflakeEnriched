
<!DOCTYPE html>

<html>
  <head><link rel="shortcut icon" type="image/x-icon" href="SnowflakeEnriched.ico" />
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Introducing Snowflake &#8212; Contents v1.0 documentation</title>
    <link rel="stylesheet" href="static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="static/my.css" type="text/css" />
    <link rel="stylesheet" href="static/copybutton.css" type="text/css" />
    <script id="documentation_options" data-url_root="./" src="static/documentation_options.js"></script>
    <script src="static/jquery.js"></script>
    <script src="static/underscore.js"></script>
    <script src="static/doctools.js"></script>
    <script src="static/language_data.js"></script>
    <script src="static/clipboard.min.js"></script>
    <script src="static/copybutton.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Introducing data platform" href="IntroducingDataplatform.html" />
    <link rel="prev" title="Introduction" href="Introduction.html" />
   
  <link rel="stylesheet" href="static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <div class="section" id="introducing-snowflake">
<h1>Introducing Snowflake<a class="headerlink" href="#introducing-snowflake" title="Permalink to this headline"></a></h1>
<p>Snowflake is a fully-managed elastic cloud data warehousing service.
It handles infrastructure, optimization, availability, and data protection.
It is a cloud-based SaaS (Software-as-a-Service) data management solution that makes it possible for
organizations to:</p>
<ul class="simple">
<li><p>Bring all their business data together in one place for analysis.</p></li>
<li><p>Allow all applications, analysts, or even customers to have shared access to the data.</p></li>
<li><p>Focus on analyzing data without worrying about hardware, software, or database tuning.</p></li>
<li><p>Utilize the SQL skills, the community has already built.</p></li>
<li><p>Leverage the existing ecosystem of tools to manage, extract transform load (<strong>ETL</strong>) or extract load transform (<strong>ELT</strong>) process.</p></li>
<li><p>Integrate the current business intelligence stack like Tableau, PowerBI, and other open-source tools like D3.js and Plotly seamlessly.</p></li>
</ul>
<div class="section" id="snowflake-in-a-nutshell">
<h2>Snowflake in a nutshell<a class="headerlink" href="#snowflake-in-a-nutshell" title="Permalink to this headline"></a></h2>
<p>Snowflake data warehousing is built with cloud-first architecture.
Snowflake core is built with separation of storage and compute. Because of this,
it allows infinite scalability for data storage and compute resources.
This also enables organizations to execute data load pipelines and create analytical insights at the same time,
without competing for resources. Snowflake also provides all the capabilities needed for
enabling data lake, data exchange, data applications, and data engineering.</p>
<p>Snowflake is a cloud-agnostic platform providing, unified data management across multiple cloud service providers like Azure,
AWS, and GCP. In other words, the Snowflake data warehouse can be built on top of Amazon web services, Microsoft Azure
cloud infrastructure, or Google cloud.</p>
<div class="section" id="architecture">
<h3>Architecture<a class="headerlink" href="#architecture" title="Permalink to this headline"></a></h3>
<p>The Snowflake architecture consists of three layers.
The following diagram shows Snowflake architecture.</p>
<p>Source: <a class="reference external" href="https://www.snowflake.com/blog/5-reasons-to-love-snowflakes-architecture-for-your-data-warehouse/" target="_blank">https://www.snowflake.com/blog/5-reasons-to-love-snowflakes-architecture-for-your-data-warehouse/</a></p>
<div class="figure align-center">
<img alt="images/snowflakeArchitecture.JPG" src="images/snowflakeArchitecture.JPG" />
</div>
<p><strong>Cloud Services:</strong> This layer coordinates and handles all other services in Snowflake,
including sessions, authentication, SQL compilation, encryption, etc.</p>
<p><strong>Compute resources:</strong> Snowflake provides the ability to create virtual warehouses,
which are basically compute clusters provisioned behind the scenes.
These virtual warehouses are used to load data, run queries, or do both concurrently.</p>
<p><strong>Storage resources:</strong>  The actual underlying file system is backed by the Snowflake account, in which
all data is encrypted, compressed, and distributed to optimize performance.
Snowflake also provides excellent data durability, and availability.</p>
</div>
<div class="section" id="virtual-warehouse">
<h3>Virtual warehouse<a class="headerlink" href="#virtual-warehouse" title="Permalink to this headline"></a></h3>
<p>Snowflake defines a virtual warehouse as a cluster of compute resources.
The warehouse provides all the resources like CPU, memory, and temporary storage
required to start using Snowflake. This warehouse defaults to auto-suspend mode if there are no activities.</p>
<p>All data in Snowflake is maintained in database objects. Each database consists of one or more schemas.
Schemas are logical groupings of database objects like tables, views, and functions.</p>
</div>
<div class="section" id="advantages">
<h3>Advantages<a class="headerlink" href="#advantages" title="Permalink to this headline"></a></h3>
<ul class="simple">
<li><p>Faster, easier to use, scalable, and far more flexible than other data platforms.</p></li>
<li><p>Can be started quickly and delivers high-quality performance.</p></li>
<li><p>Solves concurrency issues with its multi-cluster warehouse architecture.</p></li>
<li><p>Loads and processes the data quickly.</p></li>
<li><p>Supports auto-scaling, big data workload, and data sharing.</p></li>
<li><p>Easily scale up the virtual warehouse and provides elasticity as per needs.</p></li>
<li><p>Intuitive and simple interface.</p></li>
<li><p>Fully automated platform.</p></li>
</ul>
</div>
<div class="section" id="data-features">
<h3>Data features<a class="headerlink" href="#data-features" title="Permalink to this headline"></a></h3>
<p>In Snowflake, data can be ingested from various sources in variety of data
formats like CSV, Parquet, ORC, and XML data sources.
It supports JSON to a great extent, and furthermore:</p>
<ul class="simple">
<li><p>Provides full support to create views on different data formats.</p></li>
<li><p>Allows securely sharing data with other snowflake accounts.</p></li>
<li><p>Permits replication and syncing databases across multiple accounts in different regions.</p></li>
<li><p>Enables time travel functions to query the history of data changes over a period of time.</p></li>
</ul>
</div>
<div class="section" id="data-sharing">
<h3>Data sharing<a class="headerlink" href="#data-sharing" title="Permalink to this headline"></a></h3>
<p>Snowflake data sharing is a powerful and simple feature to share
the data from one account to another account.
The data producer can provide access to the live data without copying
or moving the data. The data consumer can query the shared data from
the producer without any performance bottlenecks because of multi-cluster shared data architecture.</p>
</div>
<div class="section" id="security">
<h3>Security<a class="headerlink" href="#security" title="Permalink to this headline"></a></h3>
<p>Snowflake provides out-of-the-box network access control via network policies,
allowing to restrict account access to specific IP addresses.
Snowflake offers Role Based Access Control. Users can be
defined in the Snowflake as well as external identity providers
such as Active Directory and Okta. External identities allow federation of user management.
We can set the privileges to specific roles. These roles are assigned to the users.</p>
</div>
<div class="section" id="time-travel">
<h3>Time travel<a class="headerlink" href="#time-travel" title="Permalink to this headline"></a></h3>
<p>The time travel feature allows querying the historical data of a table.
If we delete or update data rows, we can retrieve the status of the
table at point in time before we executed that statement.
The time travel is applied by default on all tables in Snowflake
for 1 day and can be configured up to 90 days.</p>
</div>
<div class="section" id="connectivity">
<h3>Connectivity<a class="headerlink" href="#connectivity" title="Permalink to this headline"></a></h3>
<p>Snowflake provides a few different methods to create database connectivity:</p>
<ul class="simple">
<li><p>ODBC and JDBC drivers can directly access a Snowflake instance.</p></li>
<li><p>Web-based worksheets can be leveraged within the Snowflake account.</p></li>
<li><p>SnowSQL CLI is also used to establish connectivity to Snowflake.</p></li>
</ul>
</div>
</div>
<div class="section" id="data-load-tools">
<h2>Data load tools<a class="headerlink" href="#data-load-tools" title="Permalink to this headline"></a></h2>
<p>Snowflake data load can be achieved using:</p>
<blockquote>
<div><ul class="simple">
<li><p>Web interface to load a small amount of data.</p></li>
<li><p>SnowSQL CLI for the bulk load.</p></li>
<li><p>Snowpipe to automate the load of large dataset across multiple platforms.</p></li>
</ul>
</div></blockquote>
<div class="figure align-center">

</div>
<p>Snowflake supports a wide range of third-party tools like Informatica, Talend, and Azure Data Factory.</p>
<div class="section" id="snowflake-web">
<h3>Snowflake web<a class="headerlink" href="#snowflake-web" title="Permalink to this headline"></a></h3>
<p>The Snowflake web interface provides a convenient wizard to load data to a specific table.
Using the LOAD button, we can easily ingest limited amount of data.
The wizard simplifies the load by combining the staging and data loading phases into a single
operation. Also, it automatically deletes the staged file after loading.</p>
</div>
<div class="section" id="snowsql-cli-client">
<h3>SnowSQL CLI Client<a class="headerlink" href="#snowsql-cli-client" title="Permalink to this headline"></a></h3>
<p>SnowSQL CLI is the command-line client interface for Snowflake. It executes SQL queries
and performs all DDL and DML operations. It is an easy way to access Snowflake from the command line and has
the same capabilities as the Snowflake UI. It also allows to load data from local file system  to Snowflake
stage.</p>
</div>
<div class="section" id="snowpipe">
<h3>Snowpipe<a class="headerlink" href="#snowpipe" title="Permalink to this headline"></a></h3>
<p>Snowpipe is a mechanism to load high frequency or streaming data.
It can load data in a near real-time manner. It also allows for the processing of data in micro-batches.
Micro-batch processing is similar to traditional batch processing where data is usually processed as a group.
Snowpipe is a serverless architecture
and does not use virtual warehouse resources. It has its own resources that are managed by Snowflake instances.</p>
<p>Snowpipe makes REST API available to load data from:</p>
<blockquote>
<div><ul class="simple">
<li><p>Amazon Web Services (AWS) - Amazon S3</p></li>
<li><p>Google Cloud Platform - Cloud Storage</p></li>
<li><p>Microsoft Azure Blob Storage, and Azure Data Lake Storage Gen2 (ADLS-Gen2)</p></li>
<li><p>Hadoop and Spark big data platforms</p></li>
</ul>
</div></blockquote>
</div>
</div>
<div class="section" id="environment-setup">
<h2>Environment setup<a class="headerlink" href="#environment-setup" title="Permalink to this headline"></a></h2>
<p>First, we need to create the Snowflake account using URL <a class="reference external" href="https://signup.snowflake.com/" target="_blank" >https://signup.snowflake.com/</a>.</p>
<div class="figure align-center">
<img alt="images/SnowflakeSubscription.JPG" src="images/SnowflakeSubscription.JPG" />
</div>
<p>Once the account is created, Snowflake adds a primary sample dataset. It provides Snowflake web interface
access URL like '<strong>vXXXXXX.east-us-2.azure.snowflakecomputing.com</strong>',
based on the account and region selected while creating the account.
This URL can be used to connect to the Snowflake web by keying username and password.
Once logged in you can see the Snowflake account home page as shown below.</p>
<div class="figure align-center">
<img alt="images/Snowflakepane.JPG" src="images/Snowflakepane.JPG" />
</div>
<p>This interface looks similar to other SQL toolsets with navigation bar at top of the page.
Database pane is on the left side, worksheet in the middle, and results pane at the bottom.
Worksheet area is used to write and execute the SQL Code.
Results of the query execution are rendered in the result pane.</p>
<p>Now we are ready to execute our first Snowflake command. Let us add a new database called <strong>IPEDS</strong> here.</p>
<p>Create new worksheet by choosing Worksheets option from top navigational menu.
Go to worksheet, use the following command in worksheet area and execute the command by clicking Run button.</p>
<div class="highlight-rst notranslate"><div class="highlight"><pre><span></span>CREATE DATABASE IPEDS;
</pre></div>
</div>
<p>New database is added.
The IPEDS database appears in the existing collection of Snowflake databases.
Throughout this book IPEDS database is used for data ingestion, transformation, and consumption.
Before running any SQL commands from this book, always use the newly created database.</p>
<p>The following command can be executed to change the context of the current
database and schema to the newly created IPEDS database.</p>
<div class="highlight-rst notranslate"><div class="highlight"><pre><span></span>USE DATABASE IPEDS;
USE SCHEMA PUBLIC;
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><em>Make sure to change the database context to IPEDS with public schema before executing any SQL from the book</em>.</p>
</div>
<div class="section" id="id1">
<h3>SnowSQL CLI Client<a class="headerlink" href="#id1" title="Permalink to this headline"></a></h3>
<p>We are ready to work in the newly added Snowflake database.
Client components are required to connect to this database and stage files from a local machine. Now, let us install Snowflake CLI on our machine.</p>
<div class="figure align-center">
<img alt="images/SnowflakeCLI.png" src="images/SnowflakeCLI.png" />
</div>
<p>Login to Snowflake account, choose Help and download option to get SnowSQL CLI.</p>
<blockquote>
<div><div class="line-block">
<div class="line">Windows version of SnowSQL can also be downloaded from:</div>
<div class="line"><a class="reference external" href="https://sfc-repo.snowflakecomputing.com/snowsql/bootstrap/1.2/windows_x86_64/index.html" target="_blank">https://sfc-repo.snowflakecomputing.com/snowsql/bootstrap/1.2/windows_x86_64/index.html</a>.</div>
</div>
<div class="line-block">
<div class="line">You can find installation and configuration instructions under:</div>
<div class="line"><a class="reference external" href="https://docs.snowflake.com/en/user-guide/snowsql-install-config.html"" target="_blank" target="_blank" >https://docs.snowflake.com/en/user-guide/snowsql-install-config.html</a>.</div>
</div>
</div></blockquote>
<p>After SnowSQL CLI is installed, go to <strong>Command prompt</strong>.
Use the following command to connect Snowflake from the Windows command line.</p>
<div class="highlight-rst notranslate"><div class="highlight"><pre><span></span>snowsql -a accountName -u userName -d databaseName -s schemaName

snowsql -a newlycreatedsnowflakeAccount -u UserID -d IPEDS -s public
Password:<span class="gs">*****</span>*
</pre></div>
</div>
<p>SnowSQL CLI will connect to Snowflake instance. Database interaction can be started
from the SQL prompt as shown below.</p>
<div class="figure align-center">
<img alt="images/SnowCLILogin.jpg" src="images/SnowCLILogin.jpg" />
</div>
<p>We are ready to use database and query. Let us run our first SQL command.</p>
<div class="highlight-rst notranslate"><div class="highlight"><pre><span></span>SELECT CURRENT_DATABASE(), CURRENT_SCHEMA();
</pre></div>
</div>
<p>We should get the database and schema names as shown below.</p>
<div class="figure align-center">
<img alt="images/SnowCLIResults.JPG" src="images/SnowCLIResults.JPG" />
</div>
<p>To terminate the current session, run the following command.</p>
<div class="highlight-rst notranslate"><div class="highlight"><pre><span></span>!exit
</pre></div>
</div>
<p>We have successfully created Snowflake account
and learned how to run queries in Snowflake web using worksheet.
Also connected to the Snowflake account from desktop using SnowSQL CLI.
Now, we are ready to work on our project.</p>
</div>
</div>
<div class="section" id="staged-area">
<h2>Staged area<a class="headerlink" href="#staged-area" title="Permalink to this headline"></a></h2>
<p>A stage is a temporary storage area in the Snowflake warehouse.
It supports both internal and external staged areas.
External stages are storage locations outside the Snowflake environment in another cloud storage location.
It could be Amazon S3 storage, Microsoft Azure Storage, or Google Cloud Storage buckets. This provides greater
flexibility for accessing the data in Snowflake.
The internal stage stores data files within Snowflake. Internal stages can be either permanent or temporary.
The data files can be loaded to Snowflake's internal storage using <strong>PUT</strong> command from SnowSQL CLI.
Internal storage is classified into three categories as listed below.</p>
<p>Internal storage copies data within the Snowflake warehouse as shown below.</p>
<div class="figure align-center">
<img alt="images/InternalStorage.jpg" src="images/InternalStorage.jpg" />
</div>
<div class="section" id="user-stage">
<h3>User stage<a class="headerlink" href="#user-stage" title="Permalink to this headline"></a></h3>
<p>Each Snowflake user is attached to the default stage for storing data files.
The user stage is only accessible by the specific user
and it supports multiple file formats like CSV, JSON, ORC, and Parquet.</p>
<p>The user stages are referenced using &#64;~.</p>
<p>For example, use <strong>list &#64;~</strong> to list the files in a user stage.</p>
</div>
<div class="section" id="table-stage">
<h3>Table stage<a class="headerlink" href="#table-stage" title="Permalink to this headline"></a></h3>
<p>Each table has a Snowflake stage allocated for storing files. Multiple users can access a
single table stage area.
Table stages are storage locations held within a table object.
This is helpful when files only need to be loaded into the specific table.
Table stages do not support setting file format options.</p>
<p>The table stages are referenced using <strong>&#64;%&lt;tableName&gt;</strong>.</p>
<p>Execute command <strong>list &#64;%test</strong> to list the files in a table stage.</p>
</div>
<div class="section" id="internal-named-stage">
<h3>Internal named stage<a class="headerlink" href="#internal-named-stage" title="Permalink to this headline"></a></h3>
<p>This stage is mostly recommended for loading data from the files into Snowflake tables.
It is available to load
multiple tables. Multiple users have access to the internal named stage.
File formats can be specified while creating an internal named stage.
Throughout this book, we have used internal named stages for storing files of various data formats.</p>
</div>
</div>
<div class="section" id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Permalink to this headline"></a></h2>
<p>This chapter has covered Snowflake architectural components, data features, and the various tools used in data loading.
Multiple ways of connecting to Snowflake services alongside learning about the supported data formats
are outlined in this chapter. We also created Snowflake account,
learned how to connect, create database, and execute our first set of queries.
It also summarized various methods for loading files into
Snowflake using the user stage, table stage, and internal named stage database objects.</p>
<p>In the next chapter, we will cover modern-day data platforms, data formats, and input datasets used throughout this book.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 33%" />
<col style="width: 33%" />
<col style="width: 33%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference external" href="./index.html">&nbsp;&nbsp;<img src= "images/tableofcontents.png" width="25px" height="20px"><font color="blue"><b>Table of contents</b> </font></a></p></td>
<td><p><a class="reference external" href="./Introduction.html">&nbsp;&nbsp;<img src= "images/previouschapter.png" width="30px" height="20px"><font color="blue"><b>Previous chapter</b> </font></a></p></td>
<td><p><a class="reference external" href="./IntroducingDataplatform.html">&nbsp;&nbsp;<img src= "images/nextchapter.png" width="30px" height="20px"><font color="blue"><b>Next chapter</b> </font></a></p></td>
</tr>
</tbody>
</table>
</div>
</div>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="index.html">Contents</a></h1>









<p class="caption"></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="Preface.html">Preface</a></li>
<li class="toctree-l1"><a class="reference internal" href="Introduction.html">Introduction</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Introducing Snowflake</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#snowflake-in-a-nutshell">Snowflake in a nutshell</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#architecture">Architecture</a></li>
<li class="toctree-l3"><a class="reference internal" href="#virtual-warehouse">Virtual warehouse</a></li>
<li class="toctree-l3"><a class="reference internal" href="#advantages">Advantages</a></li>
<li class="toctree-l3"><a class="reference internal" href="#data-features">Data features</a></li>
<li class="toctree-l3"><a class="reference internal" href="#data-sharing">Data sharing</a></li>
<li class="toctree-l3"><a class="reference internal" href="#security">Security</a></li>
<li class="toctree-l3"><a class="reference internal" href="#time-travel">Time travel</a></li>
<li class="toctree-l3"><a class="reference internal" href="#connectivity">Connectivity</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#data-load-tools">Data load tools</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#snowflake-web">Snowflake web</a></li>
<li class="toctree-l3"><a class="reference internal" href="#snowsql-cli-client">SnowSQL CLI Client</a></li>
<li class="toctree-l3"><a class="reference internal" href="#snowpipe">Snowpipe</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#environment-setup">Environment setup</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id1">SnowSQL CLI Client</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#staged-area">Staged area</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#user-stage">User stage</a></li>
<li class="toctree-l3"><a class="reference internal" href="#table-stage">Table stage</a></li>
<li class="toctree-l3"><a class="reference internal" href="#internal-named-stage">Internal named stage</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#summary">Summary</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="IntroducingDataplatform.html">Introducing data platform</a></li>
<li class="toctree-l1"><a class="reference internal" href="CSVIngestion.html">CSV ingestion</a></li>
<li class="toctree-l1"><a class="reference internal" href="JSONIngestion.html">JSON ingestion</a></li>
<li class="toctree-l1"><a class="reference internal" href="ORCIngestion.html">ORC ingestion</a></li>
<li class="toctree-l1"><a class="reference internal" href="ParquetIngestion.html">Parquet ingestion</a></li>
<li class="toctree-l1"><a class="reference internal" href="SemiStructuredDataIngestion.html">Multi-format ingestion</a></li>
<li class="toctree-l1"><a class="reference internal" href="PipelineOrchestration.html">Workflow orchestration</a></li>
<li class="toctree-l1"><a class="reference internal" href="BusinessInsights.html">Business insights</a></li>
<li class="toctree-l1"><a class="reference internal" href="Summary.html">Summary</a></li>
<li class="toctree-l1"><a class="reference internal" href="Abbreviations.html">Abbreviations</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
      <li>Previous: <a href="Introduction.html" title="previous chapter">Introduction</a></li>
      <li>Next: <a href="IntroducingDataplatform.html" title="next chapter">Introducing data platform</a></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" /> <br><br> <img src="images/frontpage.JPG" >
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
 <script type="text/javascript">
    $(document).ready(function() {
        $(".toggle > *").hide();
        $(".toggle .header").show();
        $(".toggle .header").click(function() {
            $(this).parent().children().not(".header").toggle(400);
            $(this).parent().children(".header").toggleClass("open");
        })
    });
</script>

  </body>
</html>